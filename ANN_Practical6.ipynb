{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: Define the sigmoid function and its derivative\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Step 2: Define the training function for the neural network\n",
        "def train_neural_network(X, y, learning_rate, epochs):\n",
        "    # Step 3: Initialize the weights and biases with random values\n",
        "    input_neurons = X.shape[1]\n",
        "    hidden_neurons = 4\n",
        "    output_neurons = y.shape[1]\n",
        "    hidden_weights = np.random.uniform(size=(input_neurons, hidden_neurons))\n",
        "    hidden_bias = np.random.uniform(size=(1, hidden_neurons))\n",
        "    output_weights = np.random.uniform(size=(hidden_neurons, output_neurons))\n",
        "    output_bias = np.random.uniform(size=(1, output_neurons))\n",
        "\n",
        "    # Step 4: Perform the training iterations\n",
        "    for i in range(epochs):\n",
        "        # Step 4.1: Forward propagation\n",
        "        hidden_layer_activation = np.dot(X, hidden_weights) + hidden_bias\n",
        "        hidden_layer_output = sigmoid(hidden_layer_activation)\n",
        "        output_layer_activation = np.dot(hidden_layer_output, output_weights) + output_bias\n",
        "        predicted_output = sigmoid(output_layer_activation)\n",
        "\n",
        "        # Step 4.2: Backward propagation\n",
        "        error = y - predicted_output\n",
        "        d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
        "        error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
        "        d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "        # Step 4.3: Update the weights and biases\n",
        "        output_weights += np.dot(hidden_layer_output.T, d_predicted_output) * learning_rate\n",
        "        output_bias += np.sum(d_predicted_output, axis=0, keepdims=True) * learning_rate\n",
        "        hidden_weights += np.dot(X.T, d_hidden_layer) * learning_rate\n",
        "        hidden_bias += np.sum(d_hidden_layer, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    # Step 5: Return the predicted output\n",
        "    return predicted_output\n",
        "\n",
        "# Function to convert a number to its binary representation\n",
        "def number_to_binary(num):\n",
        "    binary_str = bin(num)[2:]\n",
        "    binary_list = [int(bit) for bit in binary_str]\n",
        "    padded_binary = np.pad(binary_list, (5 - len(binary_list), 0), 'constant') if len(binary_list) < 5 else binary_list[:5]\n",
        "    return padded_binary\n",
        "\n",
        "# Function to convert a number to its one-hot encoded output\n",
        "def number_to_output(num):\n",
        "    if num == 0:\n",
        "        return [1, 0, 0, 0]\n",
        "    elif num == 1:\n",
        "        return [0, 1, 0, 0]\n",
        "    elif num == 2:\n",
        "        return [0, 0, 1, 0]\n",
        "    elif num == 39:\n",
        "        return [0, 0, 0, 1]\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported number\")\n",
        "\n",
        "# Function to generate training data for the specified numbers\n",
        "def generate_training_data(numbers):\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for num in numbers:\n",
        "        binary_representation = number_to_binary(num)\n",
        "        X_train.append(binary_representation)\n",
        "        y_train.append(number_to_output(num))\n",
        "    return np.array(X_train), np.array(y_train)\n",
        "\n",
        "# Train the neural network to recognize the numbers\n",
        "training_numbers = [0, 1, 2, 39]\n",
        "X_train, y_train = generate_training_data(training_numbers)\n",
        "predicted_output = train_neural_network(X_train, y_train, learning_rate=0.1, epochs=10000)\n",
        "\n",
        "print(\"Predicted outputs for training data:\")\n",
        "print(predicted_output)\n",
        "\n",
        "# Test the neural network\n",
        "def test_neural_network(X_test, hidden_weights, hidden_bias, output_weights, output_bias):\n",
        "    predicted_output = sigmoid(np.dot(sigmoid(np.dot(X_test, hidden_weights) + hidden_bias), output_weights) + output_bias)\n",
        "    return predicted_output\n",
        "\n",
        "# Test data for numbers 0, 1, 2, 39\n",
        "X_test = np.array([\n",
        "    [1, 1, 1, 0, 1],  # Representing 0\n",
        "    [0, 1, 1, 0, 0],  # Representing 1\n",
        "    [1, 1, 0, 1, 1],  # Representing 2\n",
        "    [1, 0, 0, 1, 1]   # Representing 39\n",
        "])\n",
        "\n",
        "# Provide the weights and biases for testing\n",
        "hidden_weights = np.array([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8], [0.9, 0.10, 0.11, 0.12], [0.13, 0.14, 0.15, 0.16], [0.17, 0.18, 0.19, 0.20]])\n",
        "hidden_bias = np.array([[0.21, 0.22, 0.23, 0.24]])\n",
        "output_weights = np.array([[0.25, 0.26, 0.27, 0.28], [0.29, 0.30, 0.31, 0.32], [0.33, 0.34, 0.35, 0.36], [0.37, 0.38, 0.39, 0.40]])\n",
        "output_bias = np.array([[0.41, 0.42, 0.43, 0.44]])\n",
        "\n",
        "print(\"\\nPredicted outputs for test data:\")\n",
        "print(test_neural_network(X_test, hidden_weights, hidden_bias, output_weights, output_bias))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOIq-wGjN9c6",
        "outputId": "796d1f3e-c73a-4982-9911-51fdff34872d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted outputs for training data:\n",
            "[[9.54118339e-01 2.86632753e-02 3.19994595e-02 1.99416534e-04]\n",
            " [3.51640808e-02 9.62618326e-01 4.44054789e-05 2.74770420e-02]\n",
            " [3.38501084e-02 7.57081284e-05 9.60617832e-01 3.28480748e-02]\n",
            " [9.97205723e-06 2.98309270e-02 2.71275845e-02 9.63252690e-01]]\n",
            "\n",
            "Predicted outputs for test data:\n",
            "[[0.80872466 0.81533131 0.82176006 0.82801221]\n",
            " [0.79433043 0.8008659  0.80724409 0.81346557]\n",
            " [0.80510913 0.81166166 0.81804368 0.82425627]\n",
            " [0.78097748 0.78734228 0.79357101 0.79966373]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Another One"
      ],
      "metadata": {
        "id": "R6mEmBdAEkrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: Define the sigmoid function and its derivative\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Step 2: Define the training function for the neural network\n",
        "def train_neural_network(X, y, learning_rate, epochs):\n",
        "    # Step 3: Initialize the weights and biases with random values\n",
        "    input_neurons = X.shape[1]\n",
        "    hidden_neurons = 4\n",
        "    output_neurons = y.shape[1]\n",
        "    hidden_weights = np.random.uniform(size=(input_neurons, hidden_neurons))\n",
        "    hidden_bias = np.random.uniform(size=(1, hidden_neurons))\n",
        "    output_weights = np.random.uniform(size=(hidden_neurons, output_neurons))\n",
        "    output_bias = np.random.uniform(size=(1, output_neurons))\n",
        "\n",
        "    # Step 4: Perform the training iterations\n",
        "    for i in range(epochs):\n",
        "        # Step 4.1: Forward propagation\n",
        "        hidden_layer_activation = np.dot(X, hidden_weights) + hidden_bias\n",
        "        hidden_layer_output = sigmoid(hidden_layer_activation)\n",
        "        output_layer_activation = np.dot(hidden_layer_output, output_weights) + output_bias\n",
        "        predicted_output = sigmoid(output_layer_activation)\n",
        "\n",
        "        # Step 4.2: Backward propagation\n",
        "        error = y - predicted_output\n",
        "        d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
        "        error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
        "        d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "        # Step 4.3: Update the weights and biases\n",
        "        output_weights += np.dot(hidden_layer_output.T, d_predicted_output) * learning_rate\n",
        "        output_bias += np.sum(d_predicted_output, axis=0, keepdims=True) * learning_rate\n",
        "        hidden_weights += np.dot(X.T, d_hidden_layer) * learning_rate\n",
        "        hidden_bias += np.sum(d_hidden_layer, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    # Step 5: Return the predicted output\n",
        "    return predicted_output\n",
        "\n",
        "# Example usage\n",
        "X = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1],[0, 1, 0]])\n",
        "y = np.array([[1], [1], [0], [0], [1]])\n",
        "\n",
        "# Train the Neural Network\n",
        "predicted_output = train_neural_network(X, y, learning_rate=0.1, epochs=10000)\n",
        "print(predicted_output)\n"
      ],
      "metadata": {
        "id": "d18HZnyiEnHy",
        "outputId": "58994d75-fdac-4c4b-ad8f-97992e6d8086",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.98146692]\n",
            " [0.98849108]\n",
            " [0.01369423]\n",
            " [0.01970438]\n",
            " [0.98604797]]\n"
          ]
        }
      ]
    }
  ]
}